{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Cornelis de Jager n8891974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Import ML libraries\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Set a random state value\n",
    "rs = 10\n",
    "\n",
    "#import libraries to visualize decision trees\n",
    "import pydot\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "# Ignore Warnings and ignore them\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoricalPlot(cat, cat2 = 'IsBadBuy'): # Cat is the carigorical as a string i.e 'Size'\n",
    "    pd.crosstab(data[cat],data[cat2]).plot(kind=\"bar\")\n",
    "    \n",
    "def CreateAveragedColumn (A, B):\n",
    "    C = [np.nan] * len( A )\n",
    "    for i in range(len(A)):\n",
    "        C[i] = (A[i] + B[i])/2\n",
    "    \n",
    "    return C\n",
    "\n",
    "def IdentifyOutliers (column):\n",
    "    data_described = column.describe()\n",
    "    Q1 = data_described[\"25%\"]\n",
    "    Q3 = data_described[\"75%\"]\n",
    "    IQR = Q3-Q1\n",
    "    lowerLimit = Q1 - 1.5 * IQR\n",
    "    upperLimit = Q3 + 1.5 * IQR\n",
    "    output = [np.nan] * len( column )\n",
    "    for i in range(len(column)):\n",
    "        value = column[i]\n",
    "        if value < lowerLimit or value > upperLimit:\n",
    "            output[i] = True\n",
    "        else:\n",
    "            output[i] = False\n",
    "    return output\n",
    "\n",
    "def analyse_feature_importance(dm_model, feature_names, n_to_display=5):\n",
    "    # grab feature importances from the model\n",
    "    importances = dm_model.feature_importances_\n",
    "    \n",
    "    # sort them out in descending order\n",
    "    indices = np.argsort(importances)\n",
    "    indices = np.flip(indices, axis=0)\n",
    "\n",
    "    # limit to 20 features, you can leave this out to print out everything\n",
    "    indices = indices[:n_to_display]\n",
    "\n",
    "    for i in indices:\n",
    "        print(feature_names[i], ':', importances[i])\n",
    "        \n",
    "# Define a function to find the root node\n",
    "def getTreeInfo(model, feature_names):\n",
    "    features  = [feature_names[i] for i in model.tree_.feature]\n",
    "    print(\"Root feature is \", features[0])\n",
    "    print(\"Competing featues are \", features[1], 'and ', features[2])\n",
    "    print(\"Number of nodes is \", model.tree_.node_count)\n",
    "    \n",
    "def ImputeColumn (column) : \n",
    "    from sklearn.preprocessing import Imputer\n",
    "    imp = Imputer(missing_values=0, strategy=\"mean\", axis=0)\n",
    "    column = imp.fit_transform(column.reshape(-1, 1)).ravel()\n",
    "    \n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessing (data):\n",
    "    print(\"Pre-Processing Step\")\n",
    "    \n",
    "    # Check if there are any missing target variables\n",
    "    if data['IsBadBuy'].isna().any():\n",
    "        print(\"Missing Target Variables\")\n",
    "    else:\n",
    "        print(\"No missing Target Variables\")\n",
    "    \n",
    "    \n",
    "    # Handle Bad Columns drop Columns\n",
    "    data.drop(['PRIMEUNIT', 'AUCGUART', 'WheelTypeID', 'ForSale', 'PurchaseDate'], \n",
    "              axis=1, \n",
    "              inplace=True)\n",
    "    \n",
    "\n",
    "    # Handle Missing Values\n",
    "    i = 0            # Python's indexing starts at zero\n",
    "    for item in data['TopThreeAmericanName']:   # Python's for loops are a \"for each\" loop \n",
    "        if data['TopThreeAmericanName'][i] == np.nan and  data['Make'][i] == 'Hyundai':\n",
    "            data['TopThreeAmericanName'][i] = 'HYUNDAI'\n",
    "        i += 1\n",
    "        \n",
    "    i = 0            # Python's indexing starts at zero\n",
    "    for item in data['TopThreeAmericanName']:   # Python's for loops are a \"for each\" loop \n",
    "        if data['TopThreeAmericanName'][i] == np.nan and  data['Make'][i] == 'Jeep':\n",
    "            data['TopThreeAmericanName'][i] = 'JEEP'\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "    \"\"\" DOES THIS HAVE TO BE THERE \"\"\"\n",
    "    # print(data.groupby(['TopThreeAmericanName'])['Make'].value_counts())\n",
    "    \"\"\" DOES THIS HAVE TO BE THERE \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    # Standardise the capitilization across all object rows\n",
    "    obj_cols = data.select_dtypes(include='object').columns # Create a list of col names\n",
    "    for i in obj_cols:              # Interate over the obj_cols list\n",
    "        data[i] = data[i].str.upper()   # Convert all strings to uppercase  \n",
    "    # Standardize USA to AMERICA\n",
    "    data['Nationality'].replace({'USA' : 'AMERICAN'}, inplace = True)\n",
    "    \n",
    "    # Turn Transmission into a binary variable with Auto = 1 and Manual = 0\n",
    "    data.rename({'Transmission' : 'Auto'}, axis = 1, inplace = True)\n",
    "    # Replace binary columns with 1s and 0s\n",
    "    data['Auto'].replace({'MANUAL' : 0, 'AUTO' : 1}, inplace=True)\n",
    "    \n",
    "    # Remove NOT AVAIL in color and place it in the NaN section\n",
    "    data['Color'].replace({'NOT AVAIL': np.nan}, inplace = True)\n",
    "    \n",
    "    \n",
    "    \"\"\" I'll have to check with teach if this is correct\n",
    "    #This is the significance test for VNST\n",
    "    # Check to see if VNST is a statisically significant variable\n",
    "    # Create a distribution of IsBuyBad for VNST\n",
    "    VNST_badBuy = pd.crosstab(data['IsBadBuy'], data['VNST']).loc[0]\n",
    "    VNST_goodBuy = pd.crosstab(data['IsBadBuy'], data['VNST']).loc[1]\n",
    "    categoricalPlot('VNST')\n",
    "    \n",
    "    # Use a Chi2 test to test if there is any corrilation between them, if there is\n",
    "    # (p < 0.05) discarde the variable\n",
    "    fScore, pValue = stats.f_oneway(VNST_badBuy, VNST_goodBuy)\n",
    "    print(\"The pValaue is \" + str(pValue) + \" which is significant enough to reject null hypothesis\")\n",
    "    \"\"\"\n",
    "    print(\"Drop VNST due to statistical insignificance\")\n",
    "    data.drop('VNST', axis=1, inplace = True)\n",
    "    \n",
    "    # Seperate the Size feature into Size and Body\n",
    "    tempSize = data['Size'].str.split(' ', expand = True) # Create temp var with split column\n",
    "    data['Size'] = tempSize[0] # Save the temp var back into data\n",
    "    data['Body'] = tempSize[1] # Save the temp var back into data\n",
    "    data['Body'].fillna('CITY', inplace = True) # Assume any other cars are 'City'\n",
    "    \n",
    "    \n",
    "    data.loc[data.Size == 'VAN', 'Body'] = 'Van' # Convert Van into a body type\n",
    "    data.loc[data.Size == 'VAN', 'Body'] =  np.nan # Take van away from size, shouldn't matter once OH is done\n",
    "    \n",
    "\n",
    "    # Replace all non 0, 1 values in IsOnlineSale to 1\n",
    "    maskOnlineSale = data['IsOnlineSale'] != 0 # Any value that isn't 0 will be set to 1\n",
    "    data.loc[maskOnlineSale, 'IsOnlineSale'] = 1 # Set the values to 1\n",
    "    \n",
    "    \n",
    "    # Converting the TimeStamp into Quater\n",
    "    Quarter = [] # Create empty string\n",
    "    for i, _ in enumerate(data.PurchaseTimestamp): # Loop over the entire dataset\n",
    "        # Convert the epoch datetime into the quater and append to list\n",
    "        Quarter.append(pd.Timestamp(data.PurchaseTimestamp.loc[i], unit = 's').quarter)        \n",
    "    data['Quarter'] = Quarter # Create the column with list\n",
    "    data.drop('PurchaseTimestamp', axis=1, inplace = True) # Drop old TimeStamp\n",
    "    \n",
    "    \"\"\" This will take care of any Null values we don't specifically take care of\n",
    "    by replaceing the missing data with data from the same distibution\"\"\"\n",
    "    conv = []\n",
    "    for i in data.columns: # Loop over dataset\n",
    "        if data[i].isna().any() == True: # Check to see if there is a NaN is the feature\n",
    "            dist = data[i].value_counts(normalize=True) # Find the distrabution of the column\n",
    "            missing = data[i].isna() # Find where the NaN are\n",
    "            # Replace the NaNs with values from the same distrabution of the column\n",
    "            data.loc[missing, i] = np.random.choice(dist.index, size=len(data[missing]),p=dist.values)       \n",
    "            conv.append(i)\n",
    "    print(\"Converted all of \" , conv, \"s missing values into the same distrubution\")\n",
    "    \n",
    "    \n",
    "    data[\"MMRAcquisitionAuctionAveragePrice\"].fillna(data[\"MMRAcquisitionAuctionAveragePrice\"].mean(), inplace=True)\n",
    "    data[\"MMRAcquisitionAuctionCleanPrice\"].fillna(data[\"MMRAcquisitionAuctionCleanPrice\"].mean(), inplace=True)\n",
    "    data[\"MMRAcquisitionRetailAveragePrice\"].fillna(data[\"MMRAcquisitionRetailAveragePrice\"].mean(), inplace=True)\n",
    "    data[\"MMRAcquisitonRetailCleanPrice\"].fillna(data[\"MMRAcquisitonRetailCleanPrice\"].mean(), inplace=True)\n",
    "    data[\"MMRCurrentAuctionAveragePrice\"].fillna(data[\"MMRCurrentAuctionAveragePrice\"].mean(), inplace=True)\n",
    "    data[\"MMRCurrentAuctionCleanPrice\"].fillna(data[\"MMRCurrentAuctionCleanPrice\"].mean(), inplace=True)\n",
    "    data[\"MMRCurrentRetailAveragePrice\"].fillna(data[\"MMRCurrentRetailAveragePrice\"].mean(), inplace=True)\n",
    "    data[\"MMRCurrentRetailCleanPrice\"].fillna(data[\"MMRCurrentRetailCleanPrice\"].mean(), inplace=True)\n",
    "    \n",
    "#     print(np.corrcoef(data[\"MMRAcquisitionAuctionAveragePrice\"], data[\"MMRAcquisitionAuctionCleanPrice\"]))\n",
    "#     print(np.corrcoef(data[\"MMRAcquisitionRetailAveragePrice\"], data[\"MMRAcquisitonRetailCleanPrice\"]))\n",
    "#     print(np.corrcoef(data[\"MMRCurrentAuctionAveragePrice\"], data[\"MMRCurrentAuctionCleanPrice\"]))\n",
    "#     print(np.corrcoef(data[\"MMRCurrentRetailAveragePrice\"], data[\"MMRCurrentRetailCleanPrice\"])) \n",
    "    \n",
    "    \"\"\" Create the new columns \"\"\"\n",
    "    data[\"AcquisitionAuctionprice\"] = CreateAveragedColumn(data[\"MMRAcquisitionAuctionAveragePrice\"], data[\"MMRAcquisitionAuctionCleanPrice\"])\n",
    "    data[\"AcquisitionRetailPrice\"] = CreateAveragedColumn(data[\"MMRAcquisitionRetailAveragePrice\"], data[\"MMRAcquisitonRetailCleanPrice\"])\n",
    "    data[\"MMRCurrentAuctionPrice\"] = CreateAveragedColumn(data[\"MMRCurrentAuctionAveragePrice\"], data[\"MMRCurrentAuctionCleanPrice\"])\n",
    "    data[\"MMRCurrentRetailPrice\"] = CreateAveragedColumn(data[\"MMRCurrentRetailAveragePrice\"], data[\"MMRCurrentRetailCleanPrice\"])\n",
    "    \n",
    "    data.drop('MMRAcquisitionAuctionAveragePrice', inplace = True, axis = 1)\n",
    "    data.drop('MMRAcquisitionAuctionCleanPrice', inplace = True, axis = 1)\n",
    "    data.drop('MMRAcquisitonRetailCleanPrice', inplace = True, axis = 1)\n",
    "    data.drop('MMRCurrentAuctionAveragePrice', inplace = True, axis = 1)\n",
    "    data.drop('MMRCurrentAuctionCleanPrice', inplace = True, axis = 1)\n",
    "    data.drop('MMRCurrentRetailAveragePrice', inplace = True, axis = 1)\n",
    "    data.drop('MMRCurrentRetailCleanPrice', inplace = True, axis = 1)\n",
    "    data.drop('MMRAcquisitionRetailAveragePrice', inplace = True, axis = 1)\n",
    "    \n",
    "    \n",
    "     # Now do histograms\n",
    "    print(data[\"AcquisitionAuctionprice\"].hist())\n",
    "    print(data[\"AcquisitionRetailPrice\"].hist())\n",
    "    print(data[\"MMRCurrentAuctionPrice\"].hist())\n",
    "    print(data[\"MMRCurrentRetailPrice\"].hist())\n",
    "    \n",
    "    ## Identify and Remove outiers\n",
    "    outliers = (IdentifyOutliers(data[\"AcquisitionAuctionprice\"]) and\n",
    "                IdentifyOutliers(data[\"AcquisitionRetailPrice\"]) and\n",
    "                IdentifyOutliers(data[\"MMRCurrentAuctionPrice\"]) and\n",
    "                IdentifyOutliers(data[\"MMRCurrentRetailPrice\"]))\n",
    "    \n",
    "    print(data[\"AcquisitionAuctionprice\"].hist())\n",
    "    print(\"\")\n",
    "    print(data[\"AcquisitionRetailPrice\"].hist())\n",
    "    print(\"\")\n",
    "    print(data[\"MMRCurrentAuctionPrice\"].hist())\n",
    "    print(\"\")\n",
    "    print(data[\"MMRCurrentRetailPrice\"].hist())\n",
    "    \n",
    "    \n",
    "    # Select lines that aren't outliers\n",
    "    num_lines =  len(data[\"MMRCurrentRetailPrice\"])\n",
    "    data = data[[not i for i in outliers]]\n",
    "    print (\"Lines Removed: \", num_lines - len(data[\"MMRCurrentRetailPrice\"]))\n",
    "    \n",
    "    \n",
    "    \"\"\" This should be the last thing done \"\"\"\n",
    "    # Convert all categorical variables into one hot representations\n",
    "    \n",
    "    print(\"The number of features before one hot encoding is \" + str(data.shape[1]))\n",
    "    data_OH = pd.get_dummies(data, columns = ['Auction', 'Make', 'Color', 'VehYear', \n",
    "                                              'Nationality', 'Size', 'Body', 'TopThreeAmericanName', \n",
    "                                              'WheelType', 'Quarter'])\n",
    "    print(\"The number of features after one hot encoding is \" + str(data_OH.shape[1]))\n",
    "    \n",
    "    return data, data_OH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Processing Step\n",
      "No missing Target Variables\n",
      "Drop VNST due to statistical insignificance\n",
      "Converted all of  ['Auction', 'VehYear', 'Make', 'Color', 'Auto', 'WheelType', 'VehOdo', 'Nationality', 'Size', 'TopThreeAmericanName', 'MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice', 'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice', 'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice', 'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice', 'MMRCurrentRetailRatio', 'VehBCost', 'WarrantyCost', 'Body'] s missing values into the same distrubution\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "Lines Removed:  502\n",
      "The number of features before one hot encoding is 21\n",
      "The number of features after one hot encoding is 95\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_raw = pd.read_csv(\"Kick.csv\", # Read the csv into a DF\n",
    "                   index_col = 'PurchaseID', \n",
    "                   na_values = ('?',  '#VALUE!'))\n",
    "\n",
    "data, data_OH = PreProcessing(data_raw) # PreProcess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
